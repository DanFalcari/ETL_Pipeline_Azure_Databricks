# Projeto de ETL com Azure, Databricks e Arquitetura Medallion

## üìå Descri√ß√£o do Projeto

Este projeto implementa um pipeline de **ETL (Extract, Transform, Load)** utilizando a **Arquitetura Medallion** no **Azure Databricks**, integrando diferentes servi√ßos do Azure para ingest√£o, processamento e armazenamento de dados estruturados e n√£o estruturados.

![imagem](imagens/Medallion_Architecture.PNG)

##  Arquitetura Medallion

A **Arquitetura Medallion** organiza os dados em tr√™s camadas, garantindo qualidade e estrutura√ß√£o progressiva:

###  Camada Bronze (Raw Data)

- Armazena os dados brutos exatamente como foram recebidos.
- Mant√©m o hist√≥rico e possibilita reprocessamentos.
- Dados provenientes de diferentes fontes s√£o carregados no **Azure Data Lake Storage (Container)**.
- Montagem da camada Bronze via **Databricks**:

###  Camada Silver (Cleansed Data)

- Processamento e limpeza dos dados utilizando **Azure Databricks** (Apache Spark).
- Remo√ß√£o de valores inconsistentes, duplicados e transforma√ß√£o dos tipos de dados.
- Os dados s√£o armazenados em **Azure SQL Database** e **Azure Data Lake Storage**.

###  Camada Gold (Refined Data)

- Cont√©m dados agregados e enriquecidos para an√°lise e visualiza√ß√£o.
- Prontos para consumo por **Power BI**, relat√≥rios e modelos preditivos.

##  Tecnologias e Servi√ßos Utilizados

###  **Azure Resources**

- **Azure Resource Group**: Agrupamento dos recursos para melhor gerenciamento.
- **Azure Storage Account**: Armazena dados brutos na camada Bronze.
- **Azure Databricks**: Plataforma para processamento distribu√≠do e transforma√ß√£o de dados.
- **Azure SQL Database**: Armazena dados transformados na camada Silver.
- **Azure Container Instances**: Para orquestra√ß√£o de execu√ß√£o de jobs de ETL.
- **Azure Key Vault**: Gerenciamento seguro de credenciais.

###  **Ferramentas e Linguagens**

- **Python (Pandas, PySpark)**
- **SQL (Azure SQL, SQL Database)**
- **Apache Spark (Databricks Notebooks)**

##  Fluxo de Processamento ETL

1. **Extra√ß√£o (Extract)**: Coleta de dados de diversas fontes e armazenamento na camada Bronze (Azure Data Lake Storage).
2. **Transforma√ß√£o (Transform)**: Processamento com Databricks para limpeza, tratamento e enriquecimento dos dados.
3. **Carga (Load)**: Armazenamento dos dados refinados na camada Gold para an√°lise e consumo.
4. **Envio para o Azure SQL Database**:



## Organiza√ß√£o do projeto

```

‚îú‚îÄ‚îÄ .gitignore         <- Arquivos e diret√≥rios a serem ignorados pelo Git
‚îú‚îÄ‚îÄ ambiente.yml       <- O arquivo de requisitos para reproduzir o ambiente de an√°lise
‚îú‚îÄ‚îÄ LICENSE            <- Licen√ßa de c√≥digo aberto (MIT)
‚îú‚îÄ‚îÄ README.md          <- README principal para desenvolvedores que usam este projeto.
|
‚îú‚îÄ‚îÄ dados              <- Arquivos de dados para o projeto.
|
|
‚îú‚îÄ‚îÄ notebooks          <- Jupyter Notebooks com tratamento e an√°lise dos dados.
‚îÇ
|   ‚îî‚îÄ‚îÄsrc             <- C√≥digo-fonte para uso neste projeto.
|      ‚îÇ
|      ‚îú‚îÄ‚îÄ __init__.py  <- Torna um m√≥dulo Python
|      ‚îî‚îÄ‚îÄconfig.py    <- Configura√ß√µes b√°sicas do projeto
|    
|
‚îú‚îÄ‚îÄ referencias        <- Dicion√°rios de dados
|
‚îú‚îÄ‚îÄ relatorios         <- An√°lises geradas em HTML, PDF, LaTeX, etc.
‚îÇ   ‚îî‚îÄ‚îÄ imagens        <- Imagens usadas no projeto
```

## Configura√ß√£o do ambiente

1. Fa√ßa o clone do reposit√≥rio.

    ```bash
    git clone git@github.com:DanFalcari/Projeto_diabetes.git
    ```

2. Crie um ambiente virtual para o seu projeto utilizando o conda.

      ```bash
      conda env create -f ambiente.yml --name diabetes 
      ```
